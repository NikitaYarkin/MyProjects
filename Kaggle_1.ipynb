{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be0a06-df31-4b2c-bf2b-18e825328f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    " 4.\n",
    "\n",
    "# На основе алгоритма из предыдущего домашнего задания постройте стекинг (используйте 5-кратную кросс-валидацию) для всех моделей \n",
    "#с наилучшими подобранными параметрами. В качестве тренировочных данных используйте весь датасет train.csv, \n",
    "#а в качестве тестовых - весь датасет test.csv. Сделайте прогноз мета-алгоритма для test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29e7f1-a460-40f2-a243-f3d9d4570943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0995aa63-db7a-4907-8fbf-70daa44acd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brf_fitest_params=  {'min_samples_leaf': 3, 'n_estimators': 70} best_score=  0.8215366267026551\n",
      "gbc_fitest_params=  {'learning_rate': 0.1} gbc_best_score=  0.8136965664427844\n",
      "svc_fitest_params=  {'C': 0.1, 'kernel': 'linear'} svc_best_score=  0.8091770761408574\n",
      "lr_fitest_params=  {'C': 0.5} lr_best_score=  0.8091833532107213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load in the train and test datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#print(train)\n",
    "#print(test)\n",
    "\n",
    "# Store our passenger ID for easy access\n",
    "PassengerId = test['PassengerId']\n",
    "\n",
    "full_data = [train, test]\n",
    "\n",
    "# Gives the length of the name\n",
    "train['Name_length'] = train['Name'].apply(len)\n",
    "test['Name_length'] = test['Name'].apply(len)\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "# Create a New feature CategoricalAge\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "# Create a new feature Title, containing the titles of passenger names\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "\n",
    "# Feature selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "\n",
    "test  = test.drop( ['PassengerId','Name', 'Ticket', 'Cabin', 'SibSp'], axis = 1)\n",
    "\n",
    "#test_1=\n",
    "\n",
    "\n",
    "\n",
    "targets = train['Survived']\n",
    "data = train.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_train=targets\n",
    "x_train=data\n",
    "x_test=test\n",
    "\n",
    "\n",
    "y_test= targets.iloc[:418]\n",
    "\n",
    "\n",
    "\n",
    "train=x_train\n",
    "valid= x_test\n",
    "train_true=y_train\n",
    "valid_true=y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "                                     train_test_split,\n",
    "                                     StratifiedKFold)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lr_params = {'C': np.arange(0.5, 1, 0.1)}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=17,shuffle=True)\n",
    "\n",
    "\n",
    "rfc_params = {'n_estimators': [70], # RandomForestClassifier\n",
    "              'min_samples_leaf': [3]}\n",
    "\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=17)\n",
    "grid_search_rf = GridSearchCV(rf_model, rfc_params,cv=5)\n",
    "rf_fit=grid_search_rf.fit(train, train_true)\n",
    "\n",
    "brf_fitest_params = grid_search_rf.best_params_\n",
    "best_score = grid_search_rf.best_score_\n",
    "print('brf_fitest_params= ',brf_fitest_params,'best_score= ',best_score)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc_params = {'learning_rate': [0.1]}\n",
    "\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(random_state=17)\n",
    "grid_search_gbc= GridSearchCV(gbc_model, gbc_params,cv=5)\n",
    "gbc_fit=grid_search_gbc.fit(train, train_true)\n",
    "\n",
    "gbc_fitest_params = grid_search_gbc.best_params_\n",
    "gbc_best_score = grid_search_gbc.best_score_\n",
    "print('gbc_fitest_params= ',gbc_fitest_params,'gbc_best_score= ',gbc_best_score)\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svc_params = {'kernel': ['linear'], # SVC\n",
    "             'C': [0.1]}\n",
    "\n",
    "svc_model = svm.SVC(random_state=17)\n",
    "grid_search_svc= GridSearchCV(svc_model, svc_params,cv=5)\n",
    "svc_fit=grid_search_svc.fit(train, train_true)\n",
    "\n",
    "svc_fitest_params = grid_search_svc.best_params_\n",
    "svc_best_score = grid_search_svc.best_score_\n",
    "print('svc_fitest_params= ',svc_fitest_params,'svc_best_score= ',svc_best_score)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr_params = {'C': [0.5]}\n",
    "\n",
    "lr_model = LogisticRegression(random_state=17)\n",
    "grid_search_lr= GridSearchCV(lr_model, lr_params,cv=5)\n",
    "lr_fit=grid_search_lr.fit(train, train_true)\n",
    "\n",
    "lr_fitest_params = grid_search_lr.best_params_\n",
    "lr_best_score = grid_search_lr.best_score_\n",
    "print('lr_fitest_params= ',lr_fitest_params,'lr_best_score= ',lr_best_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_params = {'n_estimators':[95],\n",
    "              'learning_rate': [0.4],\n",
    "              'min_child_weight': [8],\n",
    "              'subsample': [0.3],\n",
    "              'reg_lambda':[1]  }\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "#meta_models = [rf_fit, lr_fit, gbc_fit, svc_fit]\n",
    "\n",
    "\n",
    "# Определим базовые алгоритмы\n",
    "meta_models = [rf_fit, lr_fit, gbc_fit, svc_fit]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1fe00194-64ab-4cb0-86d6-239573e1b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta__params=  {'learning_rate': 0.4, 'min_child_weight': 8, 'n_estimators': 95, 'reg_lambda': 1, 'subsample': 0.3} meta_best_score=  0.8854811374050591\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Создадим пустую матрицу для мета-признаков\n",
    "meta_mtrx_m = np.empty((x_train.shape[0], len(meta_models)))\n",
    "\n",
    "# # Получим предсказания от базовых алгоритмов на валидационном наборе\n",
    "for n, model in enumerate(meta_models):\n",
    "     meta_mtrx_m[:, n] = model.predict(x_train)\n",
    "\n",
    "\n",
    "\n",
    "# # Создадим мета-алгоритм XGBoost\n",
    "meta = XGBClassifier(random_state=17)\n",
    "\n",
    "# # Создадим объект GridSearchCV\n",
    "grid_search_meta = GridSearchCV(meta, xgb_params, cv=5)\n",
    "\n",
    "# # Обучим мета-алгоритм на мета-признаках\n",
    "grid_search_meta.fit(meta_mtrx_m, y_train)\n",
    "\n",
    "# #print(valid_true )\n",
    "#grid_search_meta.fit(meta_mtrx_m, valid_true)\n",
    "\n",
    "# # Получим лучшие параметры\n",
    "best_params = grid_search_meta.best_params_\n",
    "\n",
    "\n",
    "\n",
    "meta_best_score = grid_search_meta.best_score_\n",
    "print('meta__params= ',best_params,'meta_best_score= ',meta_best_score)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d15bdc-4d4f-4d3c-bdad-69d8b4c37897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcce0ce-0d3d-4984-b136-4b63bbd92527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.\n",
    "\n",
    "#С помощью нижеприведенной функции сформируйте файл посылки для соревнования и отправьте на Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18061fc1-4067-4c4b-87ae-8d2566870ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1bf53837-d26a-4cc3-8ec3-5e6d01453f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Загрузите данные PassengerID\n",
    "passenger_ids = pd.read_csv('test.csv')['PassengerId']\n",
    "#print(passenger_ids)\n",
    "# Сделайте прогнозы\n",
    "predictions = meta_predict  # замените это фактическими прогнозами\n",
    "\n",
    "#Создайте DataFrame с прогнозами и PassengerID\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,\n",
    "    'Survived': predictions\n",
    "})\n",
    "submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e6cdd-8f8c-4639-8717-6929af0b969f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5d4c1a79-0cff-44fe-a772-391e56de9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_to_submission_file(predictions, passenger_ids, out_file='Submission.csv', columns=['PassengerID', 'Survived']):\n",
    "    predicted_df = pd.DataFrame(np.array([passenger_ids,  meta_predict]).T, columns=columns)\n",
    "    predicted_df.to_csv(out_file, index=False)\n",
    "   #predicted_df.to_csv(\"C:/output.csv\", index=False)\n",
    "write_to_submission_file(predictions,passenger_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1dd77-8974-4d3b-afe6-47a106937832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d24019-8600-4eaa-9251-2af27165ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.\n",
    "\n",
    "#Каков результат score, полученного на соревновании?\n",
    "\n",
    "Ваш ответ: Score: 0.76315\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ff237-ef62-4ff7-8ff2-e9700a6c16b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5945b0-1e90-4b44-939c-1493eec45308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7f897-2c19-4736-b03d-e59016d0c708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
